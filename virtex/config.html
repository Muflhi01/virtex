<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-120523111-2"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-120523111-2');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Inconsolata&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Ubuntu+Mono&display=swap" rel="stylesheet">


  <title>virtex.config &mdash; virtex 1.4 documentation</title>

      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="virtex.factories" href="factories.html" />
    <link rel="prev" title="How to evaluate on downstream tasks?" href="usage/downstream.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> virtex
          </a>
              <div class="version">
                1.4
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="usage/setup_dependencies.html">How to setup this codebase?</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage/model_zoo.html">VirTex Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage/pretrain.html">How to train your VirTex model?</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage/downstream.html">How to evaluate on downstream tasks?</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">virtex.config</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#config-references">Config References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="factories.html">virtex.factories</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">virtex.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">virtex.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">virtex.modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">virtex.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">virtex.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">virtex.model_zoo</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">virtex</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>virtex.config</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/virtex/config.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="virtex-config">
<h1>virtex.config<a class="headerlink" href="#virtex-config" title="Permalink to this headline"></a></h1>
<hr><span class="target" id="module-virtex.config"></span><dl class="py class">
<dt class="sig sig-object py" id="virtex.config.Config">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">virtex.config.</span></span><span class="sig-name descname"><span class="pre">Config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config_file</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">override_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/kdexd/virtex/blob/master/virtex/config.py#L6-L236"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#virtex.config.Config" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>This class provides package-wide configuration management. It is a
nested dict-like structure with nested keys accessible as attributes. It
contains sensible default values, which can be modified by (first) a YAML
file and (second) a list of attributes and values.</p>
<p>An instantiated object is immutable: modifying any attribute is illegal.
You must override required parameter values either through <code class="docutils literal notranslate"><span class="pre">config_file</span></code>
or <code class="docutils literal notranslate"><span class="pre">override_list</span></code> arguments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config_file</strong> – Path to a YAML file containing config parameters.</p></li>
<li><p><strong>config_override</strong> – A list of sequential attributes and values of parameters.
This happens after overriding from YAML file.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Let a YAML file named “config.yaml” specify these parameters to override:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">OPTIM</span><span class="p">:</span>
<span class="n">BATCH_SIZE</span><span class="p">:</span> <span class="mi">512</span>
<span class="n">LR</span><span class="p">:</span> <span class="mf">0.01</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">_C</span> <span class="o">=</span> <span class="n">Config</span><span class="p">(</span><span class="s2">&quot;config.yaml&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;OPTIM.BATCH_SIZE&quot;</span><span class="p">,</span> <span class="mi">1024</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_C</span><span class="o">.</span><span class="n">LR</span>  <span class="c1"># default: 0.001</span>
<span class="go">0.01</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">BATCH_SIZE</span>  <span class="c1"># default: 256, file: 512</span>
<span class="go">1024</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="virtex.config.Config.dump">
<span class="sig-name descname"><span class="pre">dump</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/kdexd/virtex/blob/master/virtex/config.py#L221-L227"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#virtex.config.Config.dump" title="Permalink to this definition"></a></dt>
<dd><p>Save config at the specified file path.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> – Path to save config file (YAML).</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="config-references">
<h2>Config References<a class="headerlink" href="#config-references" title="Permalink to this headline"></a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">  1</span><span class="n">_C</span><span class="o">.</span><span class="n">RANDOM_SEED</span> <span class="o">=</span> <span class="mi">0</span>
<span class="linenos">  2</span><span class="c1"># Train with Automatic Mixed Precision (native PyTorch).</span>
<span class="linenos">  3</span><span class="n">_C</span><span class="o">.</span><span class="n">AMP</span> <span class="o">=</span> <span class="kc">True</span>
<span class="linenos">  4</span><span class="c1"># Set CUDNN deterministic flag (torch.backends.cudnn.deterministic).</span>
<span class="linenos">  5</span><span class="c1"># Setting this will ensure exact results on every run at the cost of</span>
<span class="linenos">  6</span><span class="c1"># little slowdown. Good for debugging.</span>
<span class="linenos">  7</span><span class="n">_C</span><span class="o">.</span><span class="n">CUDNN_DETERMINISTIC</span> <span class="o">=</span> <span class="kc">False</span>
<span class="linenos">  8</span><span class="c1"># Set CUDNN benchmark flag (torch.backends.cudnn.benchmark). Enables</span>
<span class="linenos">  9</span><span class="c1"># CUDNN to select fastest implementation for operations based on GPU.</span>
<span class="linenos"> 10</span><span class="c1"># May change results (in decimals) on different hardware, but faster</span>
<span class="linenos"> 11</span><span class="c1"># to train. Turn off while debugging.</span>
<span class="linenos"> 12</span><span class="n">_C</span><span class="o">.</span><span class="n">CUDNN_BENCHMARK</span> <span class="o">=</span> <span class="kc">True</span>
<span class="linenos"> 13</span>
<span class="linenos"> 14</span><span class="c1"># ---------------------------------------------------------------------</span>
<span class="linenos"> 15</span><span class="c1">#   Data paths and parameters related to dataloading.</span>
<span class="linenos"> 16</span><span class="c1"># ---------------------------------------------------------------------</span>
<span class="linenos"> 17</span><span class="n">_C</span><span class="o">.</span><span class="n">DATA</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>
<span class="linenos"> 18</span>
<span class="linenos"> 19</span><span class="c1"># Path to the dataset root, which structure as per README. Path is</span>
<span class="linenos"> 20</span><span class="c1"># assumed to be relative to project root.</span>
<span class="linenos"> 21</span><span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">ROOT</span> <span class="o">=</span> <span class="s2">&quot;datasets/coco&quot;</span>
<span class="linenos"> 22</span><span class="c1"># Path to .model file generated by ``sentencepiece``.</span>
<span class="linenos"> 23</span><span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TOKENIZER_MODEL</span> <span class="o">=</span> <span class="s2">&quot;datasets/vocab/coco_10k.model&quot;</span>
<span class="linenos"> 24</span>
<span class="linenos"> 25</span><span class="c1"># Handy config params for vocab size and indices of special tokens.</span>
<span class="linenos"> 26</span><span class="c1"># While these can be picked up from the tokenizer, having these in</span>
<span class="linenos"> 27</span><span class="c1"># the config makes it easy to create a model without instantiating too</span>
<span class="linenos"> 28</span><span class="c1"># many tokenizer instances (especially when not needed, e.g. model zoo).</span>
<span class="linenos"> 29</span><span class="c1"># These must match according to what&#39;s present in ``TOKENIZER_VOCAB``</span>
<span class="linenos"> 30</span><span class="c1"># and ``TOKENIZER_MODEL`` above.</span>
<span class="linenos"> 31</span><span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">VOCAB_SIZE</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="linenos"> 32</span><span class="c1"># Index of out-of-vocabulary (and padding) token.</span>
<span class="linenos"> 33</span><span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">UNK_INDEX</span> <span class="o">=</span> <span class="mi">0</span>
<span class="linenos"> 34</span><span class="c1"># Index of the start-of-sentence [SOS] token.</span>
<span class="linenos"> 35</span><span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">SOS_INDEX</span> <span class="o">=</span> <span class="mi">1</span>
<span class="linenos"> 36</span><span class="c1"># Index of the end-of-sentence [EOS] token.</span>
<span class="linenos"> 37</span><span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">EOS_INDEX</span> <span class="o">=</span> <span class="mi">2</span>
<span class="linenos"> 38</span><span class="c1"># Index of the word masking token. While not used for captioning, having</span>
<span class="linenos"> 39</span><span class="c1"># this extra token makes it possible to train an MLM model without</span>
<span class="linenos"> 40</span><span class="c1"># re-creating a new vocab mapping.</span>
<span class="linenos"> 41</span><span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">MASK_INDEX</span> <span class="o">=</span> <span class="mi">3</span>
<span class="linenos"> 42</span>
<span class="linenos"> 43</span><span class="c1"># Size of the image (square) to crop from original input image.</span>
<span class="linenos"> 44</span><span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">IMAGE_CROP_SIZE</span> <span class="o">=</span> <span class="mi">224</span>
<span class="linenos"> 45</span><span class="c1"># Maximum length of input caption (number of tokens).</span>
<span class="linenos"> 46</span><span class="c1"># Longer captions will be truncated up to this length.</span>
<span class="linenos"> 47</span><span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">MAX_CAPTION_LENGTH</span> <span class="o">=</span> <span class="mi">30</span>
<span class="linenos"> 48</span>
<span class="linenos"> 49</span><span class="c1"># List of image transforms (pre-processing and data augmentation) to be</span>
<span class="linenos"> 50</span><span class="c1"># applied sequentially (always or randomly) during training and</span>
<span class="linenos"> 51</span><span class="c1"># validation. Refer ``virtex/facetories.py`` for all possible transforms.</span>
<span class="linenos"> 52</span><span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">IMAGE_TRANSFORM_TRAIN</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos"> 53</span>    <span class="s2">&quot;random_resized_crop&quot;</span><span class="p">,</span>
<span class="linenos"> 54</span>    <span class="s2">&quot;horizontal_flip&quot;</span><span class="p">,</span>
<span class="linenos"> 55</span>    <span class="s2">&quot;color_jitter&quot;</span><span class="p">,</span>
<span class="linenos"> 56</span>    <span class="s2">&quot;normalize&quot;</span><span class="p">,</span>
<span class="linenos"> 57</span><span class="p">]</span>
<span class="linenos"> 58</span><span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">IMAGE_TRANSFORM_VAL</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos"> 59</span>    <span class="s2">&quot;smallest_resize&quot;</span><span class="p">,</span>
<span class="linenos"> 60</span>    <span class="s2">&quot;center_crop&quot;</span><span class="p">,</span>
<span class="linenos"> 61</span>    <span class="s2">&quot;normalize&quot;</span><span class="p">,</span>
<span class="linenos"> 62</span><span class="p">]</span>
<span class="linenos"> 63</span>
<span class="linenos"> 64</span><span class="c1"># Hyper-parameters for masked LM pretraining task. These are only used</span>
<span class="linenos"> 65</span><span class="c1"># when ``MODEL.NAME`` is &quot;masked_lm&quot;.</span>
<span class="linenos"> 66</span><span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">MASKED_LM</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>
<span class="linenos"> 67</span><span class="c1"># Fraction of tokens to choose for masking, this must be less than 1.</span>
<span class="linenos"> 68</span><span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">MASKED_LM</span><span class="o">.</span><span class="n">MASK_PROPORTION</span> <span class="o">=</span> <span class="mf">0.15</span>
<span class="linenos"> 69</span><span class="c1"># Probability to replace chosen tokens with [MASK] token.</span>
<span class="linenos"> 70</span><span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">MASKED_LM</span><span class="o">.</span><span class="n">MASK_PROBABILITY</span> <span class="o">=</span> <span class="mf">0.85</span>
<span class="linenos"> 71</span><span class="c1"># Probability to replace chosen tokens with a random token.</span>
<span class="linenos"> 72</span><span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">MASKED_LM</span><span class="o">.</span><span class="n">REPLACE_PROBABILITY</span> <span class="o">=</span> <span class="mf">0.10</span>
<span class="linenos"> 73</span>
<span class="linenos"> 74</span><span class="c1"># ---------------------------------------------------------------------</span>
<span class="linenos"> 75</span><span class="c1">#   Model architecture: visual backbone and textual head.</span>
<span class="linenos"> 76</span><span class="c1"># ---------------------------------------------------------------------</span>
<span class="linenos"> 77</span><span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>
<span class="linenos"> 78</span>
<span class="linenos"> 79</span><span class="c1"># Name of model, based on pretraining task.</span>
<span class="linenos"> 80</span><span class="c1"># Possible choices: {&quot;token_classification&quot;, &quot;multilabel_classification&quot;,</span>
<span class="linenos"> 81</span><span class="c1"># &quot;captioning&quot;, &quot;bicaptioning&quot;, &quot;masked_lm&quot;, &quot;virtex&quot;}</span>
<span class="linenos"> 82</span><span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">NAME</span> <span class="o">=</span> <span class="s2">&quot;virtex&quot;</span>
<span class="linenos"> 83</span>
<span class="linenos"> 84</span><span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">VISUAL</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>
<span class="linenos"> 85</span><span class="c1"># Name of visual backbone. Possible choices: {&quot;blind&quot;, &quot;torchvision&quot;}</span>
<span class="linenos"> 86</span><span class="c1"># Models from torchvision can be specified as shown below.</span>
<span class="linenos"> 87</span><span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">VISUAL</span><span class="o">.</span><span class="n">NAME</span> <span class="o">=</span> <span class="s2">&quot;torchvision::resnet50&quot;</span>
<span class="linenos"> 88</span><span class="c1"># Number of channels in pooled spatial features of visual backbone.</span>
<span class="linenos"> 89</span><span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">VISUAL</span><span class="o">.</span><span class="n">FEATURE_SIZE</span> <span class="o">=</span> <span class="mi">2048</span>
<span class="linenos"> 90</span><span class="c1"># Whether to load ImageNet pretrained weights into visual backbone.</span>
<span class="linenos"> 91</span><span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">VISUAL</span><span class="o">.</span><span class="n">PRETRAINED</span> <span class="o">=</span> <span class="kc">False</span>
<span class="linenos"> 92</span><span class="c1"># Whether to keep visual backbone frozen and train only textual head.</span>
<span class="linenos"> 93</span><span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">VISUAL</span><span class="o">.</span><span class="n">FROZEN</span> <span class="o">=</span> <span class="kc">False</span>
<span class="linenos"> 94</span>
<span class="linenos"> 95</span><span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">TEXTUAL</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>
<span class="linenos"> 96</span><span class="c1"># Name of textual head. Set to &quot;none&quot; for MODEL.NAME = &quot;*_classification&quot;.</span>
<span class="linenos"> 97</span><span class="c1"># Possible choices: {&quot;transdec_postnorm&quot;, &quot;transdec_prenorm&quot;}.</span>
<span class="linenos"> 98</span><span class="c1"># Architectural hyper-parameters are specified as shown above.</span>
<span class="linenos"> 99</span><span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">TEXTUAL</span><span class="o">.</span><span class="n">NAME</span> <span class="o">=</span> <span class="s2">&quot;transdec_postnorm::L1_H2048_A32_F8192&quot;</span>
<span class="linenos">100</span><span class="c1"># L = Number of layers in the transformer.</span>
<span class="linenos">101</span><span class="c1"># H = Hidden size of the transformer (embeddings, attention features).</span>
<span class="linenos">102</span><span class="c1"># A = Number of attention heads in the transformer.</span>
<span class="linenos">103</span><span class="c1"># F = Size of feedforward layers in the transformer.</span>
<span class="linenos">104</span><span class="c1"># Typically, we have (A = H / 64) and (F = 4 * H).</span>
<span class="linenos">105</span>
<span class="linenos">106</span><span class="c1"># Dropout probability for embedding, hidden features in textual head.</span>
<span class="linenos">107</span><span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">TEXTUAL</span><span class="o">.</span><span class="n">DROPOUT</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="linenos">108</span>
<span class="linenos">109</span><span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">DECODER</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>
<span class="linenos">110</span><span class="c1"># What algorithm to use for decoding. Supported values: {&quot;beam_search&quot;,</span>
<span class="linenos">111</span><span class="c1"># &quot;nucleus_sampling&quot;}.</span>
<span class="linenos">112</span><span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">DECODER</span><span class="o">.</span><span class="n">NAME</span> <span class="o">=</span> <span class="s2">&quot;beam_search&quot;</span>
<span class="linenos">113</span><span class="c1"># Number of beams to decode (1 = greedy decoding). Ignored when decoding</span>
<span class="linenos">114</span><span class="c1"># through nucleus sampling.</span>
<span class="linenos">115</span><span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">DECODER</span><span class="o">.</span><span class="n">BEAM_SIZE</span> <span class="o">=</span> <span class="mi">5</span>
<span class="linenos">116</span><span class="c1"># Size of nucleus for sampling predictions. Ignored when decoding through</span>
<span class="linenos">117</span><span class="c1"># beam search.</span>
<span class="linenos">118</span><span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">DECODER</span><span class="o">.</span><span class="n">NUCLEUS_SIZE</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="linenos">119</span><span class="c1"># Maximum length of decoded caption. Decoding may end earlier when [EOS]</span>
<span class="linenos">120</span><span class="c1"># token is sampled.</span>
<span class="linenos">121</span><span class="n">_C</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">DECODER</span><span class="o">.</span><span class="n">MAX_DECODING_STEPS</span> <span class="o">=</span> <span class="n">_C</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">MAX_CAPTION_LENGTH</span>
<span class="linenos">122</span>
<span class="linenos">123</span><span class="c1"># ---------------------------------------------------------------------</span>
<span class="linenos">124</span><span class="c1">#   Optimization hyper-parameters, default values are for pretraining</span>
<span class="linenos">125</span><span class="c1">#   our best model on bicaptioning task (COCO Captions).</span>
<span class="linenos">126</span><span class="c1"># ---------------------------------------------------------------------</span>
<span class="linenos">127</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>
<span class="linenos">128</span>
<span class="linenos">129</span><span class="c1"># Name of optimizer to use. Supported values: {&quot;sgd&quot;, &quot;adamw&quot;}.</span>
<span class="linenos">130</span><span class="c1"># AdamW uses default (beta1, beta2) values from PyTorch.</span>
<span class="linenos">131</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">OPTIMIZER_NAME</span> <span class="o">=</span> <span class="s2">&quot;sgd&quot;</span>
<span class="linenos">132</span><span class="c1"># Momentum co-efficient for SGD. Ignored for AdamW.</span>
<span class="linenos">133</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">SGD_MOMENTUM</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="linenos">134</span><span class="c1"># Weight decay co-efficient for the optimizer.</span>
<span class="linenos">135</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="linenos">136</span><span class="c1"># Regex pattern of params for which there will be no weight decay.</span>
<span class="linenos">137</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">NO_DECAY</span> <span class="o">=</span> <span class="s2">&quot;.*textual.(embedding|transformer).*(norm.*|bias)&quot;</span>
<span class="linenos">138</span><span class="c1"># Max gradient norm for clipping to avoid exploding gradients.</span>
<span class="linenos">139</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">CLIP_GRAD_NORM</span> <span class="o">=</span> <span class="mf">10.0</span>
<span class="linenos">140</span>
<span class="linenos">141</span><span class="c1"># Wrap our optimizer with Lookahead (https://arxiv.org/abs/1907.08610).</span>
<span class="linenos">142</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">LOOKAHEAD</span> <span class="o">=</span> <span class="n">CN</span><span class="p">()</span>
<span class="linenos">143</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">LOOKAHEAD</span><span class="o">.</span><span class="n">USE</span> <span class="o">=</span> <span class="kc">True</span>
<span class="linenos">144</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">LOOKAHEAD</span><span class="o">.</span><span class="n">ALPHA</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="linenos">145</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">LOOKAHEAD</span><span class="o">.</span><span class="n">STEPS</span> <span class="o">=</span> <span class="mi">5</span>
<span class="linenos">146</span>
<span class="linenos">147</span><span class="c1"># We set different learning rates for CNN (visual backbone) and rest of</span>
<span class="linenos">148</span><span class="c1"># the model. CNN LR is typically much higher for training from scratch.</span>
<span class="linenos">149</span><span class="c1"># Both LRs undergo same warmup-decay schedules.</span>
<span class="linenos">150</span>
<span class="linenos">151</span><span class="c1"># Total batch size (will be distributed evenly across GPUs).</span>
<span class="linenos">152</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">256</span>
<span class="linenos">153</span><span class="c1"># Max learning rate for CNN (visual backbone).</span>
<span class="linenos">154</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">CNN_LR</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="linenos">155</span><span class="c1"># Max learning rate for rest of the model.</span>
<span class="linenos">156</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">LR</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="linenos">157</span><span class="c1"># Number of iterations to train for, batches are randomly sampled.</span>
<span class="linenos">158</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">NUM_ITERATIONS</span> <span class="o">=</span> <span class="mi">500000</span>
<span class="linenos">159</span>
<span class="linenos">160</span><span class="c1"># Number of steps at the start of training for linear LR warmup.</span>
<span class="linenos">161</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">WARMUP_STEPS</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="linenos">162</span><span class="c1"># Learning rate annealing schedule for decay after warmup.</span>
<span class="linenos">163</span><span class="c1"># Possible choices: {&quot;none&quot;, &quot;linear&quot;, &quot;cosine&quot;, &quot;multistep&quot;}.</span>
<span class="linenos">164</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">LR_DECAY_NAME</span> <span class="o">=</span> <span class="s2">&quot;cosine&quot;</span>
<span class="linenos">165</span><span class="c1"># Steps to decay LR for &quot;multistep&quot; schedule.</span>
<span class="linenos">166</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">LR_STEPS</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos">167</span><span class="c1"># Factor to multiply with LR for &quot;multistep&quot; schedule.</span>
<span class="linenos">168</span><span class="n">_C</span><span class="o">.</span><span class="n">OPTIM</span><span class="o">.</span><span class="n">LR_GAMMA</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="linenos">169</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="usage/downstream.html" class="btn btn-neutral float-left" title="How to evaluate on downstream tasks?" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="factories.html" class="btn btn-neutral float-right" title="virtex.factories" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Karan Desai and Justin Johnson.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>